SubmissionNumber#=%=#9
FinalPaperTitle#=%=#[TACL] Cross-lingual Projected Expectation Regularization for Weakly Supervised Learning
ShortPaperTitle#=%=#Cross-lingual Projected Expectation Regularization for Weakly Supervised Learning
NumberOfPages#=%=#12
CopyrightSigned#=%=#
JobTitle#==#
Organization#==#
Abstract#==#We consider a multilingual weakly supervised learning scenario where knowledge
from annotated corpora in a resource-rich language is transferred via bitext to
guide the learning in other languages. Past approaches project labels across
bitext and use them as features or gold labels for training. We propose a new
method that projects model expectations rather than labels, which facilities
transfer of model uncertainty across language boundaries. We encode
expectations as constraints and train a discriminative CRF model using
Generalized Expectation Criteria (Mann and McCallum, 2010). Evaluated on
standard Chinese-English and German-English NER datasets, our method
demonstrates F1 scores of 64% and 60% when no labeled data is used. Attaining
the same accuracy with supervised CRFs requires 12k and 1.5k labeled sentences.
Furthermore, when combined with labeled examples, our method yields significant
improvements over state-of-the-art supervised methods, achieving best reported
numbers to date on Chinese OntoNotes and German CoNLL-03 datasets.
Author{1}{Firstname}#=%=#Mengqiu
Author{1}{Lastname}#=%=#Wang
Author{1}{Email}#=%=#mengqiu@cs.stanford.edu
Author{1}{Affiliation}#=%=#Computer Science Department, Stanford University
Author{2}{Firstname}#=%=#Christopher
Author{2}{Lastname}#=%=#Manning
Author{2}{Email}#=%=#manning@cs.stanford.edu
Author{2}{Affiliation}#=%=#Computer Science Department, Stanford University

==========
